{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !apt-get update\n",
    "# !apt-get install libsasl2-dev libsasl2-2 libsasl2-modules-gssapi-mit\n",
    "# !pip install amazon-codewhisperer-jupyterlab-ext --upgrade\n",
    "\n",
    "##############################\n",
    "\n",
    "# !pip install pymongo\n",
    "# !pip install openai\n",
    "# !pip install sasl\n",
    "# !pip install thrift\n",
    "# !pip install thrift-sasl\n",
    "# !pip install PyHive\n",
    "# !pip install SQLAlchemy\n",
    "# !pip install fuzzywuzzy\n",
    "# !pip install python-Levenshtein\n",
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "from pyhive import hive\n",
    "from sqlalchemy.engine import create_engine\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define configuration\n",
    "openai_key = \"api-key\"\n",
    "hive_host = \"url\"\n",
    "hive_port = 10000\n",
    "hive_username = \"hive\"\n",
    "hive_url = \"hive://hive@url:10000/default\"\n",
    "mongodb_url = \"mongodb://root:password@url:27017/\"\n",
    "mongodb_database = \"streamlit\"\n",
    "product_dataset = \"product\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define a function to call chat gpt \n",
    "def call_chat_gpt(query, openai_key):\n",
    "    openai.api_key = openai_key\n",
    "    response = openai.ChatCompletion.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "        ]\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get trending item from hive\n",
    "# conn = hive.Connection(host=hive_host, port=hive_port, username=hive_username)\n",
    "engine = create_engine(hive_url)\n",
    "\n",
    "keywords_df = pd.read_sql(\"SELECT * FROM trending ORDER BY trend_date DESC LIMIT 1\", engine)\n",
    "product_df = pd.read_sql(\"SELECT * FROM {}\".format(product_dataset), engine)\n",
    "product2_df = pd.read_sql(\"SELECT * FROM product2\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malta vs England, Poland vs Germany, Tesla, F1, KidZania, Kick, Fall, Azizulhasni Awang, Nicolas Jackson, Boris Johnson, Black Clover: Sword of the Wizard King, Ross Butler, Ted Lasso, Kourtney Kardashian, France, Extraction 2, Happy Father's Day, Adipurush film, England vs Australia, Spirit\n"
     ]
    }
   ],
   "source": [
    "# Proprocessing on the keywords dataframe\n",
    "keywords = keywords_df.loc[:, 'keywords'][0].replace('[', '').replace(']', '') #.replace(\"'\", '').split(',')\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_id                                       product_name  \\\n",
      "1         1.0  Samsung 7 kg Fully-Automatic Top Loading Washi...   \n",
      "2         2.0  Samsung 7 Kg Inverter 5 Star Fully-Automatic T...   \n",
      "3         3.0  Samsung 6.5 Kg 5 Star Inverter Fully-Automatic...   \n",
      "4         4.0  LG 7 Kg 5 Star Inverter Fully-Automatic Top Lo...   \n",
      "5         5.0  Samsung 7.0 Kg 5 Star Semi-Automatic Top Loadi...   \n",
      "\n",
      "  product_main_category product_sub_category  \\\n",
      "1            appliances     Washing Machines   \n",
      "2            appliances     Washing Machines   \n",
      "3            appliances     Washing Machines   \n",
      "4            appliances     Washing Machines   \n",
      "5            appliances     Washing Machines   \n",
      "\n",
      "                                  product_image_link  \\\n",
      "1  https://m.media-amazon.com/images/I/510mV2GAtk...   \n",
      "2  https://m.media-amazon.com/images/I/61Ct6+KF4A...   \n",
      "3  https://m.media-amazon.com/images/I/61Mt19diw9...   \n",
      "4  https://m.media-amazon.com/images/I/71xTwKIBX-...   \n",
      "5  https://m.media-amazon.com/images/I/71StafL7nj...   \n",
      "\n",
      "                                        product_link  product_ratings  \\\n",
      "1  https://www.amazon.in/Samsung-Fully-Automatic-...              4.4   \n",
      "2  https://www.amazon.in/Samsung-Inverter-Fully-A...              4.2   \n",
      "3  https://www.amazon.in/Samsung-Inverter-Fully-A...              4.3   \n",
      "4  https://www.amazon.in/LG-Inverter-Fully-Automa...              4.3   \n",
      "5  https://www.amazon.in/Samsung-Semi-Automatic-W...              4.2   \n",
      "\n",
      "   product_num_of_ratings  product_discount_price  product_actual_price  \n",
      "1                 24086.0                 15790.0               21000.0  \n",
      "2                  3715.0                 17990.0               22500.0  \n",
      "3                  7594.0                 16990.0               23900.0  \n",
      "4                 13541.0                 17490.0               27990.0  \n",
      "5                   852.0                 10890.0               13500.0  \n"
     ]
    }
   ],
   "source": [
    "# remove the first row of product_df as it contains only column name\n",
    "product_df = product_df.iloc[1:]\n",
    "print(product_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malta vs England: England\n",
      "Poland vs Germany: Germany\n",
      "Tesla: Model S\n",
      "F1: Mercedes\n",
      "KidZania: Roleplay\n",
      "Kick: Soccer\n",
      "Fall: Autumn\n",
      "Azizulhasni Awang: Cycling\n",
      "Nicolas Jackson: Actor\n",
      "Boris Johnson: Prime Minister\n",
      "Black Clover: Sword of the Wizard King: Anime\n",
      "Ross Butler: Actor\n",
      "Ted Lasso: TV show\n",
      "Kourtney Kardashian: Reality star\n",
      "France: Paris\n",
      "Extraction 2: Action movie\n",
      "Happy Father's Day: Gifts\n",
      "Adipurush film: Bollywood\n",
      "England vs Australia: Cricket\n",
      "Spirit: Horse\n"
     ]
    }
   ],
   "source": [
    "message = \"Can you recommend product to buy based on the given word, be short and concise, using ':' as delimiter for each item during answer: \"\n",
    "message += keywords\n",
    "# print(message)\n",
    "\n",
    "gpt_response = call_chat_gpt(message, openai_key)\n",
    "print(gpt_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['England', 'Germany', 'Model S', 'Mercedes', 'Roleplay', 'Soccer', 'Autumn', 'Cycling', 'Actor', 'Prime Minister', 'Sword of the Wizard King', 'Actor', 'TV show', 'Reality star', 'Paris', 'Action movie', 'Gifts', 'Bollywood', 'Cricket', 'Horse']\n"
     ]
    }
   ],
   "source": [
    "# extract the possible product keywords from gpt response\n",
    "product_keywords = []\n",
    "\n",
    "for line in gpt_response.split('\\n'):\n",
    "    splitted_line = line.split(':')\n",
    "    product_keywords.append(splitted_line[1].replace(' ', '', 1))\n",
    "    \n",
    "print(product_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loop through product_df to find similar product for given product_keyword\n",
    "def find_similar_product(product_keyword, products_df):\n",
    "    # max_ratio = 0\n",
    "    # max_ratio_product = None\n",
    "    recommended_product_df = pd.DataFrame(columns=[\"ratio_score\", \"product_id\"])\n",
    "    products_dict = products_df.to_dict('records') \n",
    "    \n",
    "    for row in products_dict[:]:\n",
    "        ratio = fuzz.token_sort_ratio(row['product_name'], product_keyword)\n",
    "        # print(row['product_name'])\n",
    "        # print(ratio)\n",
    "\n",
    "        # if ratio > max_ratio:\n",
    "        #     max_ratio = ratio\n",
    "        #     max_ratio_product = row['product_id']\n",
    "\n",
    "        if ratio > 60:\n",
    "            recommended_product_df = pd.concat([recommended_product_df, pd.DataFrame({\"ratio_score\": [ratio], \"product_id\": [row['product_id']]})])\n",
    "        \n",
    "    return recommended_product_df.sort_values(by=['ratio_score'], ascending=False)\n",
    "\n",
    "# find_similar_product(product_keywords[0], product_df.loc[:, ['product_id', 'product_name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to mongodb function\n",
    "def save_to_mongodb(item_to_insert, mongodb_url, database_name, collection_name):\n",
    "    client = pymongo.MongoClient(mongodb_url)\n",
    "    db = client[database_name]\n",
    "    collection = db[collection_name]\n",
    "\n",
    "    # Insert or update the product in the MongoDB collection\n",
    "    result = collection.insert_many(item_to_insert)\n",
    "    client.close()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def drop_mongodb_collection(mongodb_url, database_name, collection_name):\n",
    "    client = pymongo.MongoClient(mongodb_url)\n",
    "    db = client[database_name]\n",
    "    collection = db[collection_name]\n",
    "\n",
    "    # Drop the collection\n",
    "    result = collection.drop()\n",
    "    client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loop through product_keywords to find similar product for all keywords\n",
    "def find_all_similar_product(product_keywords, product_df):\n",
    "    all_similar_product_df = pd.DataFrame(columns=[\"ratio_score\", \"product_id\"])\n",
    "\n",
    "    for idx, product_keyword in enumerate(product_keywords):\n",
    "\n",
    "        # find similar product based on product_keyword\n",
    "        similar_product_df = find_similar_product(product_keyword, product_df)\n",
    "        all_similar_product_df = pd.concat([all_similar_product_df, similar_product_df])\n",
    "\n",
    "        if idx % 5 == 0:\n",
    "            print('{} % completed. Loading.'.format(idx / 20 * 100))\n",
    "\n",
    "        if idx == len(product_keywords) - 1:\n",
    "            print('100 % completed. Done')\n",
    "    \n",
    "    return all_similar_product_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % completed. Loading.\n",
      "25.0 % completed. Loading.\n",
      "50.0 % completed. Loading.\n",
      "75.0 % completed. Loading.\n",
      "100 % completed. Done\n"
     ]
    }
   ],
   "source": [
    "all_similar_product_id_df = find_all_similar_product(product_keywords, product_df.loc[:, ['product_id', 'product_name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[169119.0, 158309.0]\n"
     ]
    }
   ],
   "source": [
    "all_similar_product_id_list = all_similar_product_id_df.loc[:, 'product_id'].to_list()\n",
    "print(all_similar_product_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recommended_product_list = []\n",
    "\n",
    "for product_id in all_similar_product_id_list:\n",
    "    item = product_df[product_df['product_id']==product_id].to_dict('records')\n",
    "    recommended_product_list.append(item[0])\n",
    "    \n",
    "# recommended_product_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processed_keywords = {}\n",
    "processed_keywords[\"date\"] = keywords_df.loc[:, 'trend_date'][0]\n",
    "processed_keywords[\"Keywords\"] = keywords_df.loc[:, 'keywords'][0].replace('[', '').replace(']', '').split(', ')\n",
    "# print(processed_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save to Mongodb\n",
    "drop_mongodb_collection(mongodb_url, mongodb_database, \"recommended_product_1\")\n",
    "drop_mongodb_collection(mongodb_url, mongodb_database, \"trending_item\")\n",
    "\n",
    "insert_recommended_product_result = save_to_mongodb(recommended_product_list, mongodb_url, mongodb_database, \"recommended_product_1\")\n",
    "insert_trending_item_result = save_to_mongodb([processed_keywords], mongodb_url, mongodb_database, \"trending_item\")\n",
    "insert_gpt_response_result = save_to_mongodb([{'gpt_response': product_keywords, 'date': date.today().strftime(\"%Y-%m-%d\")}], mongodb_url, mongodb_database, \"gpt_response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % completed. Loading.\n",
      "25.0 % completed. Loading.\n",
      "50.0 % completed. Loading.\n",
      "75.0 % completed. Loading.\n",
      "100 % completed. Done\n"
     ]
    }
   ],
   "source": [
    "##################################################################\n",
    "# This section is for product2\n",
    "product2_df = product2_df.iloc[1:]\n",
    "\n",
    "all_similar_product2_id_df = find_all_similar_product(product_keywords, product2_df.loc[:, ['product_id', 'product_name']])\n",
    "all_similar_product2_id_list = all_similar_product2_id_df.loc[:, 'product_id'].to_list()\n",
    "\n",
    "recommended_product2_list = []\n",
    "\n",
    "for product_id in all_similar_product2_id_list:\n",
    "    item = product2_df[product2_df['product_id']==product_id].to_dict('records')\n",
    "    recommended_product2_list.append(item[0])\n",
    "\n",
    "\n",
    "drop_mongodb_collection(mongodb_url, mongodb_database, \"recommended_product_2\")\n",
    "insert_recommended_product2_result = save_to_mongodb(recommended_product2_list, mongodb_url, mongodb_database, \"recommended_product_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Logging\n",
    "with open('recommended_product_mongodb_result.log', 'a') as f:\n",
    "    f.write(\"Date: {} \\t Insert Recommended Product: {} \\t Insert Trending Item: {} \\t Insert Trending Item 2: {} \\n\"\n",
    "            .format(date.today().strftime(\"%Y-%m-%d\"), insert_recommended_product_result.acknowledged, \n",
    "                    insert_trending_item_result.acknowledged, insert_recommended_product2_result.acknowledged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# import requests\n",
    "# import pymongo\n",
    "\n",
    "# # Task 1: Call GPT API for product recommendation\n",
    "# def call_gpt_api(query):\n",
    "#     api_key = \"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\"\n",
    "#     api_endpoint = \"https://api.openai.com/v1/engines/davinci-codex/completions\"\n",
    "    \n",
    "#     headers = {\n",
    "#         \"Authorization\": f\"Bearer {api_key}\",\n",
    "#         \"Content-Type\": \"application/json\"\n",
    "#     }\n",
    "    \n",
    "#     data = {\n",
    "#         \"prompt\": query,\n",
    "#         \"max_tokens\": 50,  # Adjust the value as needed\n",
    "#         \"temperature\": 0.7  # Adjust the value as needed\n",
    "#     }\n",
    "    \n",
    "#     response = requests.post(api_endpoint, headers=headers, json=data)\n",
    "#     if response.status_code == 200:\n",
    "#         return response.json()[\"choices\"][0][\"text\"].strip()\n",
    "#     else:\n",
    "#         raise Exception(\"Failed to call GPT API\")\n",
    "\n",
    "# # Task 2: Find relevant product in data warehouse\n",
    "# def find_relevant_product(feedback):\n",
    "#     # Connect to the Hadoop data warehouse \n",
    "    \n",
    "#     # Execute the necessary query on the data warehouse\n",
    "#     # to find the relevant product based on the feedback\n",
    "    \n",
    "#     relevant_product = None  # Replace with the retrieved product information\n",
    "    \n",
    "#     return relevant_product\n",
    "\n",
    "# # Task 3: Save recommended product to MongoDB\n",
    "# def save_to_mongodb(product):\n",
    "#     client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "#     db = client[\"your_database_name\"]\n",
    "#     collection = db[\"your_collection_name\"]\n",
    "    \n",
    "#     # Transform the product data if needed\n",
    "    \n",
    "#     # Insert or update the product in the MongoDB collection\n",
    "#     collection.insert_one(product)  # Replace with appropriate insert/update operation\n",
    "    \n",
    "#     client.close()\n",
    "\n",
    "# # Example usage\n",
    "# query = \"Can you recommend a romantic movie?\"\n",
    "\n",
    "# # Task 1: Call GPT API\n",
    "# recommended_product = call_gpt_api(query)\n",
    "\n",
    "# # Task 2: Find relevant product\n",
    "# relevant_product = find_relevant_product(recommended_product)\n",
    "\n",
    "# # Task 3: Save recommended product to MongoDB\n",
    "# save_to_mongodb(relevant_product)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def call_gpt_api(query):\n",
    "#     api_key = \"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\"\n",
    "#     api_endpoint = \"https://api.openai.com/v1/engines/davinci-codex/completions\"\n",
    "    \n",
    "#     headers = {\n",
    "#         \"Authorization\": f\"Bearer {api_key}\",\n",
    "#         \"Content-Type\": \"application/json\"\n",
    "#     }\n",
    "    \n",
    "#     data = {\n",
    "#         \"prompt\": query,\n",
    "#         \"max_tokens\": 50,\n",
    "#         \"temperature\": 0.7\n",
    "#     }\n",
    "    \n",
    "#     response = requests.post(api_endpoint, headers=headers, json=data)\n",
    "#     if response.status_code == 200:\n",
    "#         return response.json()[\"choices\"][0][\"text\"].strip()\n",
    "#     else:\n",
    "#         raise Exception(\"Failed to call GPT API\")\n",
    "\n",
    "# # Example usage\n",
    "# query = \"Can you recommend a laptop under $1000 for gaming?\"\n",
    "# recommended_product = call_gpt_api(query)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
